str(df,list.len = ncol(df))

# sorting: date
df<- df[rev(order(df$order_date)),] # sorting in desc order, latest order first

f1$vintage_days<-Sys.Date()-f1$create_date

f2<- arrange(f1,desc(vintage_days))


## Sorting by multiple columns==================================
f4 <- f3 %>% arrange(Category1,-metric) # - means desc order
tbl <- tbl[order(-tbl$colToBeSorted),]

# https://stackoverflow.com/questions/47446303/sort-a-data-frame-based-on-multiple-columns-in-r

# converting Character field (originially date in excel) into date in R
br11$Date_col <- as.integer(br11$Date_col)
br11$Date_col <- as.Date(br11$Date_col,origin = "1899-12-30")


# connecting to SQL in R
library(RODBC)
library(sqldf)  
conn <-  odbcDriverConnect('driver={SQL Server};server=11.22.33.44,12345;database=DB_name;trusted_connection=true')
df <- sqlQuery(conn,paste("select top 5 * from tbl_name where col1 in ('cat1','cat2')"))


## Creating dynamic IDs============
pvt$TeamId_Boss <- "NA"
pvt<- boss_pvt %>% filter (!is.na(`MgrId`))
count= 1
# running a loop to create IDs
for ( i in 1:nrow(boss_pvt)) {
  pvt[i,"TeamId_Boss"] <- paste0("B",count)  
  count = count+1
}

## countif across rows, if the keyword matches and storing the count as new value
df$AL <- rowSums(df[,2:ncol(df)] == "AL")

## summing from column2 till last column in df, generalizing it 
df$total <- rowSums(df[,2:ncol(df)],na.rm=T)

df$avg = rowMeans(df[c("col1","col2")],na.rm=T) # means using rowmeans
df1 <- df %>% select(`col 1`,col2,col3,col4) # subsetting columns

#### Quamtiles =====================
calc <- f4 %>% filter(Category==1) %>%
  group_by(`Unit`) %>% summarise(p50 = quantile(metric,probs = .5), p75 = quantile(metric,probs = .75))

## basic ifelse=====================
f5<- f5 %>% mutate(Bucket= ifelse(cat1==1 & rate > p75,"High",
                                  ifelse(cat1==1 & rate > p50,"Medium",
                                          ifelse(cat1==0,NA,"Low"))))
                                          
#### file search basis keyword=====
setwd("E:\\folder1\folder2")
list.files()
flz <- list.files()
file_use <- flz[grepl("keyword_in_filename",flz)]
file_use
input <- read_excel(file_use,sheet="sheetName")

# rowsums with dplyr
tbl1 <- tbl1 %>% mutate(Total= rowSums(tbl1[,c('A','D,'I','M','N','S','T')],na.rm=TRUE)) # A,D,I etc are column names

# rowsums
chk$Total <- rowSums(chk[2:10],na.rm=T)

sum(df,na.rm=T)- sum(df$col1,na.rm=T) # can get sum of whole df ( if it's numeric) and also any column of df

# another way to aggregate, if not using dplyr group by , summarize, grouping by col8, summarizing cols 5,6,7
pivot<- aggregate(df[,c(5,6,7)], by=list(df[,c(8)]), FUN = sum, na.rm=T)

# rehshape===
library(reshape2)
# wide to long
costs2 <- melt(costs, id.vars = "id", variable.name = "new_col_name") # variable.name= column_name_for_values_post_collapsing_wide_columns
field_to_make_diff_columns_from

# function in R========
# applying a function to a df, scaling ratio column is already present in costs13 df, with different value for each row
cost_scale_fn <- function(inVal) {outVal = inVal * costs12$scaling_ratio}
costs13[,2:ncol(costs13)] <- lapply(costs13[,2:ncol(costs13)], cost_scale_fn) # the function is applied to selected columns

## seeing structure of all relevant df using for loop
ob_name <-as.data.frame(ls()); colnames(ob_name)[1]<-"name"
ob_name2 <- ob_name %>% filter(name %like% 'all')

names_df <- ob_name2$name

for (i in names_df) {
  df= get(i)
  print(i)
  print(nrow(df))
}


# seeing details of some df
ob_name <-as.data.frame(ls()); colnames(ob_name)[1]<-"name"
ob_name2 <- ob_name %>% filter(name %like% 'all')

names_df <- ob_name2$name
for (i in names_df) {
  df= get(i)
  print(i)
  print(nrow(df)) # should not be empty df
  print(ncol(df)) # should all have 10 columns
}

for (i in unique(tbl$zone)) 
{
  cluster<- dcast(tbl,id~segment,value.var="avgMAB",subset = .(cluster == i,segment=="Salary"))
  colSums(is.na(cluster))
  cluster[is.na(cluster)] = 0
  
  cluster_dr <- cluster
  cluster_dr$Grandtotal = sum(cluster_dr[,2])
  
  cluster_dr <- cluster_dr %>% mutate (Sal=(Sal/Grandtotal) )
  cluster_dr <- cluster_dr[,-3]
  assign(paste0(i,"_Sal_df"),cluster_dr)
}

value_group<- dcast(df,storeID~segment,value.var="total_sales",subset = .(segment == "product1"))

# loop
file_list <- list()
for (i in unique(tbl$id))
{
  
  df_id <- insig_join_use  %>% filter (id== i )
  df_id$total <- sum(df_id$val1)
  df_id$total_cx <- sum(df_id$cxflag)
  df_id$dr<- ifelse(df_id$total != 0,df_id$val1/df_id$total,
                         df_id$cxflag/df_id$total_cx)
  df_id$allotted_share<- (df_id$dr)*df_id$total_share
  id_value<- df_id
  compile_val<- id_val[,c("id","allotted_share","col1")]
  file_list[[i]]<- compile_val
}

file_appended <- do.call(rbind,file_list)


